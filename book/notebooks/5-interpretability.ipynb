{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability & Model Inspection\n",
    "\n",
    "One way to probe the models we build is to test them against the established knowledge of domain experts. In this final section, weâ€™ll explore how to build intuitions about our machine learning model and avoid pitfalls like spurious correlations. These methods for model interpretability increase our trust into models, but they can also serve as an additional level of reproducibility in our research and a valuable research artefact that can be discussed in a publication.\n",
    "\n",
    "This part of the tutorial will also go into some considerations why the feature importance of tree-based methods can serve as a start but often shouldnâ€™t be used as the sole source of truth regarding feature interpretation of our applied research.\n",
    "\n",
    "This section will introduce tools like `shap`, discuss feature importance, and manual inspection of models.\n",
    "\n",
    "First we'll split the data from [the Data notebook](/notebooks/0-basic-data-prep-and-model.html) and load the model from [the Sharing notebook](https://ml.recipes/notebooks/3-model-sharing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54158e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:22.181248Z",
     "iopub.status.busy": "2022-12-13T01:42:22.180747Z",
     "iopub.status.idle": "2022-12-13T01:42:22.193250Z",
     "shell.execute_reply": "2022-12-13T01:42:22.192754Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_FOLDER = Path(\"..\", \"..\") / \"data\"\n",
    "DATA_FILEPATH = DATA_FOLDER / \"penguins_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:22.195750Z",
     "iopub.status.busy": "2022-12-13T01:42:22.195750Z",
     "iopub.status.idle": "2022-12-13T01:42:22.596321Z",
     "shell.execute_reply": "2022-12-13T01:42:22.595821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Flipper Length (mm)</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Adelie Penguin (Pygoscelis adeliae)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Culmen Length (mm)  Culmen Depth (mm)  Flipper Length (mm)     Sex  \\\n",
       "0                39.1               18.7                181.0    MALE   \n",
       "1                39.5               17.4                186.0  FEMALE   \n",
       "2                40.3               18.0                195.0  FEMALE   \n",
       "3                36.7               19.3                193.0  FEMALE   \n",
       "4                39.3               20.6                190.0    MALE   \n",
       "\n",
       "                               Species  \n",
       "0  Adelie Penguin (Pygoscelis adeliae)  \n",
       "1  Adelie Penguin (Pygoscelis adeliae)  \n",
       "2  Adelie Penguin (Pygoscelis adeliae)  \n",
       "3  Adelie Penguin (Pygoscelis adeliae)  \n",
       "4  Adelie Penguin (Pygoscelis adeliae)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "penguins = pd.read_csv(DATA_FILEPATH)\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:22.598821Z",
     "iopub.status.busy": "2022-12-13T01:42:22.598321Z",
     "iopub.status.idle": "2022-12-13T01:42:22.766850Z",
     "shell.execute_reply": "2022-12-13T01:42:22.766350Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      2\u001b[0m num_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCulmen Length (mm)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCulmen Depth (mm)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlipper Length (mm)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m cat_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "num_features = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\"]\n",
    "cat_features = [\"Sex\"]\n",
    "features = num_features + cat_features\n",
    "target = [\"Species\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(penguins[features], penguins[target[0]], stratify=penguins[target[0]], train_size=.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:22.769350Z",
     "iopub.status.busy": "2022-12-13T01:42:22.768851Z",
     "iopub.status.idle": "2022-12-13T01:42:22.797885Z",
     "shell.execute_reply": "2022-12-13T01:42:22.797384Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from joblib import dump, load\n",
    "\n",
    "MODEL_FOLDER = Path(\"..\", \"..\") / \"model\"\n",
    "MODEL_EXPORT_FILE = MODEL_FOLDER / \"svc.joblib\"\n",
    "\n",
    "model = load(MODEL_EXPORT_FILE)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model loaded correctly, we can start diving into explainable AI, interpretability and model inspection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence for Machine Learning Interpretability\n",
    "\n",
    "The scikit-learn library provides powerful tools for understanding the relationship between features and the target variable in machine learning models, including the `PartialDependenceDisplay` and `partial_dependence` functions. These tools enable us as researchers to visualize and quantify the impact of individual features on model predictions, helping to uncover complex patterns and relationships within the data. \n",
    "\n",
    "The partial dependence plots attempt to show an \"average response\" of a model to a certain feature changing.\n",
    "\n",
    "The `PartialDependenceDisplay` function offers an intuitive way to visualize the partial dependence of the target variable on one or two features, allowing researchers to assess how the model's predictions change as the values of these features vary while marginalizing over the values of all other features. \n",
    "\n",
    "Similarly, the `partial_dependence` function computes the partial dependence of the target variable on one or more features, providing numerical values that quantify the magnitude and direction of the relationship between each feature and the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:22.800386Z",
     "iopub.status.busy": "2022-12-13T01:42:22.800386Z",
     "iopub.status.idle": "2022-12-13T01:42:22.828931Z",
     "shell.execute_reply": "2022-12-13T01:42:22.828431Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PartialDependenceDisplay, partial_dependence, plot_partial_dependence\n\u001b[0;32m      3\u001b[0m pd_results \u001b[38;5;241m=\u001b[39m partial_dependence(model, X_train\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m20\u001b[39m), num_features)\n\u001b[0;32m      4\u001b[0m pd_results\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay, partial_dependence\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "pd_results = partial_dependence(model, X_train.sample(20), num_features)\n",
    "print(pd_results.keys())\n",
    "print(f\"Example Values: {pd_results['values'][0]}, Average: {pd_results['average'][0][0].mean(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, we already have the plotting functionality available from scikit-learn directly and re-use the model we loaded earlier!\n",
    "\n",
    "We'll create a partial dependence plot for each penguin class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:22.831933Z",
     "iopub.status.busy": "2022-12-13T01:42:22.831432Z",
     "iopub.status.idle": "2022-12-13T01:42:23.247004Z",
     "shell.execute_reply": "2022-12-13T01:42:23.247004Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PartialDependenceDisplay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m----> 3\u001b[0m \u001b[43mPartialDependenceDisplay\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_estimator(model, X_train, [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m], target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(y_train\u001b[38;5;241m.\u001b[39munique())[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PartialDependenceDisplay' is not defined"
     ]
    }
   ],
   "source": [
    "PartialDependenceDisplay.from_estimator(model, X_train, [0,1,2], target=list(y_train.unique())[0])\n",
    "plt.title(f\"Partial Dependence of SVC on Penguin Features for {y_train.unique()[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.249505Z",
     "iopub.status.busy": "2022-12-13T01:42:23.249505Z",
     "iopub.status.idle": "2022-12-13T01:42:23.278512Z",
     "shell.execute_reply": "2022-12-13T01:42:23.278010Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PartialDependenceDisplay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mPartialDependenceDisplay\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_estimator(model, X_train, [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m], target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(y_train\u001b[38;5;241m.\u001b[39munique())[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PartialDependenceDisplay' is not defined"
     ]
    }
   ],
   "source": [
    "PartialDependenceDisplay.from_estimator(model, X_train, [0,1,2], target=list(y_train.unique())[1])\n",
    "plt.title(f\"Partial Dependence of SVC on Penguin Features for {y_train.unique()[1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.281510Z",
     "iopub.status.busy": "2022-12-13T01:42:23.281011Z",
     "iopub.status.idle": "2022-12-13T01:42:23.309516Z",
     "shell.execute_reply": "2022-12-13T01:42:23.309016Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PartialDependenceDisplay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mPartialDependenceDisplay\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_estimator(model, X_train, [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m], target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(y_train\u001b[38;5;241m.\u001b[39munique())[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PartialDependenceDisplay' is not defined"
     ]
    }
   ],
   "source": [
    "PartialDependenceDisplay.from_estimator(model, X_train, [0,1,2], target=list(y_train.unique())[2])\n",
    "plt.title(f\"Partial Dependence of SVC on Penguin Features for {y_train.unique()[2]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots can be very insightful, if you know how to interpret them correctly.\n",
    "\n",
    "We have the 3 features and how varying these changes the impact in predicting a specific class.\n",
    "\n",
    "Interestingly, we can see that the Culmen length for Adelie is smaller, because larger values reduce the partial dependence, Chinstrap penguins however seem to have a larger Culmen length, and Gentoo is almost unaffected by this feature!\n",
    "\n",
    "Similarly only Gentoo seems to have larger Flippers, whereas smaller flippers have a lower partial dependence for large values.\n",
    "\n",
    "I'm not a penguin expert, I just find them adorable, and I'm able to glean this interpretable information from the plots. I think is a great tool! ðŸ§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances with Tree importance vs Permutation importance\n",
    "\n",
    "Understanding feature importance is crucial in machine learning, as it helps us identify which features have the most significant impact on model predictions. \n",
    "\n",
    "Two standard methods for assessing feature importance are Tree Importance and Permutation Importance.\n",
    "Tree Importance, usually associated with tree-based models like random forests, calculates feature importances based on how frequently a feature is used to split nodes in the trees. It's a counting exercise.\n",
    "\n",
    "Features frequently selected for splitting are considered more important because they contribute more to the model's predictive performance. One benefit of Tree Importance is its computational efficiency, as feature importance can be readily obtained by training. However, Tree Importance may overestimate the importance of correlated features, features with high cardinality and randomness, and features that struggle with feature interactions.\n",
    "\n",
    "On the other hand, Permutation Importance assesses feature importance by measuring the decrease in model performance when the values of a feature are randomly shuffled. Features that, when shuffled, lead to a significant decrease in model performance are deemed more important. Permutation Importance is model-agnostic and can be applied to any type of model, making it versatile and applicable in various scenarios. Additionally, Permutation Importance accounts for feature interactions and is less biased by correlated features. However, it is computationally more expensive, especially for models with large numbers of features or complex interactions.\n",
    "\n",
    "People are interested in feature importances for several reasons. Firstly, feature importances provide insights into the underlying relationships between features and the target variable, aiding in feature selection and dimensionality reduction. \n",
    "\n",
    "Moreover, understanding feature importances helps researchers and practitioners interpret model predictions and identify potential areas for improvement or further investigation. Feature importances can also inform domain experts and stakeholders about which features are driving model decisions, enhancing transparency and trust in machine learning systems.\n",
    "\n",
    "We'll start out by training a different type of model in this section, a standard Random Forest. Then we can directly compare the tree-based feature importnace with permutation importances. The data split from [the Data notebook](/notebooks/0-basic-data-prep-and-model.html) we established earlier remains the same and the pre-processing is also the same, despite Random Forests dealing with non-normalised data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.312516Z",
     "iopub.status.busy": "2022-12-13T01:42:23.312016Z",
     "iopub.status.idle": "2022-12-13T01:42:23.340521Z",
     "shell.execute_reply": "2022-12-13T01:42:23.340021Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      3\u001b[0m num_transformer \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m      4\u001b[0m cat_transformer \u001b[38;5;241m=\u001b[39m OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42)),\n",
    "])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply plot the feature importances obtained from training the model.\n",
    "\n",
    "These will always be slightly different, due to the training process of Random Forests on randomly selected subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.343022Z",
     "iopub.status.busy": "2022-12-13T01:42:23.343022Z",
     "iopub.status.idle": "2022-12-13T01:42:23.371526Z",
     "shell.execute_reply": "2022-12-13T01:42:23.371026Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43mrf\u001b[49m\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfeature_importances_, index\u001b[38;5;241m=\u001b[39mnum_features\u001b[38;5;241m+\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar()\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "pd.Series(rf.named_steps[\"classifier\"].feature_importances_, index=num_features+['Female', 'Male']).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree-based feature importance shows the importances as the \"random forest sees them\", which means we get the `Sex` feature split into male and female from the OneHotEncoding. This also means that this categorical features is correlated strongly.\n",
    "\n",
    "We can clearly see that the `Culmen length` is the most important feature in determining which penguin we're facing. `Culmen depth` seems to be slightly less important than `Flipper length`. `Sex` seems to be entirely unimportant.\n",
    "\n",
    "Now we can use the more sophisticated permutation importance. \n",
    "\n",
    "Luckily, scikit-learn implements this feature for us and we can just import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.374527Z",
     "iopub.status.busy": "2022-12-13T01:42:23.374027Z",
     "iopub.status.idle": "2022-12-13T01:42:23.402532Z",
     "shell.execute_reply": "2022-12-13T01:42:23.402030Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[0;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m permutation_importance(\n\u001b[0;32m      4\u001b[0m     rf, X_test, y_test, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m pd\u001b[38;5;241m.\u001b[39mSeries(result\u001b[38;5;241m.\u001b[39mimportances_mean, index\u001b[38;5;241m=\u001b[39mfeatures)\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    rf, X_train, y_train, n_repeats=10, random_state=42\n",
    ")\n",
    "\n",
    "fi_rf_train = pd.Series(result.importances_mean, index=features)\n",
    "fi_rf_train.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the permutation importance gives a lower weight to `Culmen Depth` in the Random Forest and a slightly higher importance to `Sex`.\n",
    "\n",
    "Overall it's similar in that `Culmen Length` is still the most important and `Flipper length` is the second most important, while the relative importance changes somewhat. \n",
    "\n",
    "These differences can be much more pronounced in more complex models.\n",
    "\n",
    "The really neat feature is however, that we can apply this to the SVM model, which does not have internal importances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.405031Z",
     "iopub.status.busy": "2022-12-13T01:42:23.405031Z",
     "iopub.status.idle": "2022-12-13T01:42:23.433236Z",
     "shell.execute_reply": "2022-12-13T01:42:23.432735Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_importance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m(\n\u001b[0;32m      2\u001b[0m     model, X_test, y_test, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      5\u001b[0m pd\u001b[38;5;241m.\u001b[39mSeries(result\u001b[38;5;241m.\u001b[39mimportances_mean, index\u001b[38;5;241m=\u001b[39mfeatures)\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar()\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'permutation_importance' is not defined"
     ]
    }
   ],
   "source": [
    "result = permutation_importance(\n",
    "    model, X_train, y_train, n_repeats=10, random_state=42\n",
    ")\n",
    "\n",
    "fi_svm_train = pd.Series(result.importances_mean, index=features)\n",
    "fi_svm_train.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that `Culmen length` is still the most important and `Sex` is mostly unimportant, but the relative importances of `Culmen depth` and `Flipper length` change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "fi_rf_test = pd.Series(result, index=features)\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "fi_svm_test = pd.Series(result, index=features)\n",
    "\n",
    "pd.DataFrame({\"RF Train\": fi_rf_train, \"SVM Train\": fi_svm_train, \"RF Test\": fi_rf_test, \"SVM Test\": fi_svm_test}).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.435736Z",
     "iopub.status.busy": "2022-12-13T01:42:23.435736Z",
     "iopub.status.idle": "2022-12-13T01:42:23.464324Z",
     "shell.execute_reply": "2022-12-13T01:42:23.463823Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      3\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m      4\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train[num_features], y_train)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train[num_features], y_train)\n",
    "\n",
    "explainer = shap.Explainer(rf)\n",
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.467824Z",
     "iopub.status.busy": "2022-12-13T01:42:23.467324Z",
     "iopub.status.idle": "2022-12-13T01:42:23.495341Z",
     "shell.execute_reply": "2022-12-13T01:42:23.494840Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'explainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241m.\u001b[39mshap_values(X_test[num_features])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'explainer' is not defined"
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(X_test[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.497841Z",
     "iopub.status.busy": "2022-12-13T01:42:23.497841Z",
     "iopub.status.idle": "2022-12-13T01:42:23.526066Z",
     "shell.execute_reply": "2022-12-13T01:42:23.525565Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241m.\u001b[39minitjs()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shap' is not defined"
     ]
    }
   ],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.528566Z",
     "iopub.status.busy": "2022-12-13T01:42:23.528066Z",
     "iopub.status.idle": "2022-12-13T01:42:23.556704Z",
     "shell.execute_reply": "2022-12-13T01:42:23.556204Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241m.\u001b[39mforce_plot(explainer\u001b[38;5;241m.\u001b[39mexpected_value[\u001b[38;5;241m0\u001b[39m], shap_values[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], feature_names\u001b[38;5;241m=\u001b[39mnum_features)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shap' is not defined"
     ]
    }
   ],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[0][0], feature_names=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.559705Z",
     "iopub.status.busy": "2022-12-13T01:42:23.559705Z",
     "iopub.status.idle": "2022-12-13T01:42:23.587716Z",
     "shell.execute_reply": "2022-12-13T01:42:23.587215Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241m.\u001b[39mforce_plot(explainer\u001b[38;5;241m.\u001b[39mexpected_value[\u001b[38;5;241m0\u001b[39m], shap_values[\u001b[38;5;241m0\u001b[39m], feature_names\u001b[38;5;241m=\u001b[39mnum_features)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shap' is not defined"
     ]
    }
   ],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[0], feature_names=num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inspection\n",
    "\n",
    "There are several tools that work for figuring out that a model is doing what it's supposed to do. Scikit-learn classifiers mostly work out of the box, which is why we don't necessarily have to debug the models.\n",
    "\n",
    "Sometimes we have to switch off regularization in scikit-learn to achieve the model state we expect.\n",
    "\n",
    "In neural networks we are working with many moving parts. The first step is a practical step: Overfit a small batch of data on the network. This ensures that the model is capable of learning and all the connections are made as expected. This works as a first-order sense check that models are performing.\n",
    "\n",
    "A more in-depth solution for Pytorch is [Pytorch Surgeon](https://github.com/archinetai/surgeon-pytorch), which can be used to extract submodels of the complete architecture for debugging purposes.\n",
    "\n",
    "Some example code from the Pytorch Surgeon Docs (torch and surgeon are not installed to save space):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.591217Z",
     "iopub.status.busy": "2022-12-13T01:42:23.590717Z",
     "iopub.status.idle": "2022-12-13T01:42:23.618732Z",
     "shell.execute_reply": "2022-12-13T01:42:23.618231Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurgeon_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Extract, get_nodes\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from surgeon_pytorch import Extract, get_nodes\n",
    "\n",
    "class SomeModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(5, 3)\n",
    "        self.layer2 = nn.Linear(3, 2)\n",
    "        self.layer3 = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = torch.relu(self.layer1(x))\n",
    "        x2 = torch.sigmoid(self.layer2(x1))\n",
    "        y = self.layer3(x2).tanh()\n",
    "        return y\n",
    "\n",
    "model = SomeModel()\n",
    "print(get_nodes(model)) # ['x', 'layer1', 'relu', 'layer2', 'sigmoid', 'layer3', 'tanh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This enables us to extract the model at one of the nodes above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-13T01:42:23.621732Z",
     "iopub.status.busy": "2022-12-13T01:42:23.621232Z",
     "iopub.status.idle": "2022-12-13T01:42:23.649733Z",
     "shell.execute_reply": "2022-12-13T01:42:23.649232Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Extract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_ext \u001b[38;5;241m=\u001b[39m \u001b[43mExtract\u001b[49m(model, node_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m sigmoid \u001b[38;5;241m=\u001b[39m model_ext(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Extract' is not defined"
     ]
    }
   ],
   "source": [
    "model_ext = Extract(model, node_out='sigmoid')\n",
    "x = torch.rand(1, 5)\n",
    "sigmoid = model_ext(x)\n",
    "print(sigmoid) # tensor([[0.5570, 0.3652]], grad_fn=<SigmoidBackward0>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('pydata-global-2022-ml-repro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7369b48cea8bb1af6d88d25f2646d14ea11b68d7457d74f06fbf0d68480668d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
